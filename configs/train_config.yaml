training:
  phase1:
    epochs: 20
    lr: 1.0e-3
    batch_size: 64
    freeze_lstm: true
    freeze_backbone_blocks: []
  phase2:
    epochs: 30
    lr: 5.0e-4
    batch_size: 32
    freeze_lstm: false
    freeze_backbone_blocks: [0, 1, 2]
  phase3:
    epochs: 20
    lr: 1.0e-5
    batch_size: 32
    freeze_lstm: false
    freeze_backbone_blocks: []
  weight_decay: 1.0e-4
  grad_clip: 1.0
  label_smoothing: 0.1
  focal_gamma: 2.0
  focal_alpha: 0.25
  mixed_precision: true
  scheduler:
    type: cosine_annealing
    T_max: 20
    eta_min: 1.0e-7

output:
  checkpoint_dir: outputs/checkpoints
  log_dir: outputs/logs
  viz_dir: outputs/visualizations
  save_top_k: 3
