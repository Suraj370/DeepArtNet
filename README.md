# DeepArtNet ğŸ¨

> **Hierarchical Art Attribute Recognition Using CNN-RNN Architectures on the WikiArt/ArtGAN Dataset**

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Dataset](https://img.shields.io/badge/Dataset-WikiArt%2FArtGAN-purple.svg)](https://github.com/cs-chan/ArtGAN)

---

## ğŸ“– Overview

**DeepArtNet** is a deep learning system for **multi-attribute fine art classification**, recognizing three core attributes simultaneously from painting images:

| Attribute | Classes | Train Samples | Val Samples |
|-----------|---------|---------------|-------------|
| ğŸ–Œï¸ **Style** | 27 | 57,025 | 24,421 |
| ğŸ›ï¸ **Genre** | 10 | 45,503 | 19,492 |
| ğŸ‘¤ **Artist** | 23 | 13,346 | 5,706 |

The model uses a **hybrid CNN-RNN architecture**: an EfficientNet-B4 backbone extracts spatial features, which are then sequenced and processed by a Bidirectional LSTM with additive attention â€” capturing both local brushstroke detail and long-range compositional structure.

---

## ğŸ—‚ï¸ Table of Contents

- [Dataset](#-dataset)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [Training Strategy](#-training-strategy)
- [Results](#-results)
- [References](#-references)

---

## ğŸ“Š Dataset

This project uses the **WikiArt/ArtGAN** dataset, provided as pre-split CSV files.

### Included CSV Files (`data/wikiart/`)

| File | Rows | Description |
|------|------|-------------|
| `style_train.csv` | 57,025 | Training set for style classification |
| `style_val.csv` | 24,421 | Validation set for style classification |
| `genre_train.csv` | 45,503 | Training set for genre classification |
| `genre_val.csv` | 19,492 | Validation set for genre classification |
| `artist_train.csv` | 13,346 | Training set for artist classification |
| `artist_val.csv` | 5,706 | Validation set for artist classification |
| `style_class.txt` | 27 | Style class index â†’ name mapping |
| `genre_class.txt` | 10 | Genre class index â†’ name mapping |
| `artist_class.txt` | 23 | Artist class index â†’ name mapping |

### CSV Format

Each CSV row: `<StyleFolder>/<artist>_<painting>.jpg,<class_id>`

```
Impressionism/edgar-degas_landscape-on-the-orne.jpg,12
Realism/camille-corot_mantes-cathedral.jpg,21
Abstract_Expressionism/gene-davis_untitled-1979(3).jpg,0
```

### Style Classes (27)
`Abstract_Expressionism`, `Action_painting`, `Analytical_Cubism`, `Art_Nouveau`, `Baroque`, `Color_Field_Painting`, `Contemporary_Realism`, `Cubism`, `Early_Renaissance`, `Expressionism`, `Fauvism`, `High_Renaissance`, `Impressionism`, `Mannerism_Late_Renaissance`, `Minimalism`, `Naive_Art_Primitivism`, `New_Realism`, `Northern_Renaissance`, `Pointillism`, `Pop_Art`, `Post_Impressionism`, `Realism`, `Rococo`, `Romanticism`, `Symbolism`, `Synthetic_Cubism`, `Ukiyo_e`

### Genre Classes (10)
`abstract_painting`, `cityscape`, `genre_painting`, `illustration`, `landscape`, `nude_painting`, `portrait`, `religious_painting`, `sketch_and_study`, `still_life`

### Artist Classes (23)
`Albrecht_Durer`, `Boris_Kustodiev`, `Camille_Pissarro`, `Childe_Hassam`, `Claude_Monet`, `Edgar_Degas`, `Eugene_Boudin`, `Gustave_Dore`, `Ilya_Repin`, `Ivan_Aivazovsky`, `Ivan_Shishkin`, `John_Singer_Sargent`, `Marc_Chagall`, `Martiros_Saryan`, `Nicholas_Roerich`, `Pablo_Picasso`, `Paul_Cezanne`, `Pierre_Auguste_Renoir`, `Pyotr_Konchalovsky`, `Raphael_Kirchner`, `Rembrandt`, `Salvador_Dali`, `Vincent_van_Gogh`

### Class Imbalance Note

Style has severe imbalance: Impressionism (9,142) vs Synthetic_Cubism (152) â€” a 60:1 ratio. The trainer uses **Focal Loss** and **WeightedRandomSampler** to address this.

### Image Download

The CSV files are included in this repo. Images must be downloaded separately from WikiArt:

```bash
python scripts/download_images.py --output data/wikiart/images/
```

Images should be placed at: `data/wikiart/images/<StyleFolder>/<artist>_<painting>.jpg`

---

## ğŸ§  Architecture

```
Input Image (B, 3, 224, 224)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EfficientNet-B4 (CNN)   â”‚  pretrained ImageNet
â”‚  + Conv1Ã—1 Projection    â”‚  Output: (B, 512, 7, 7)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼  reshape
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Spatial Sequencer       â”‚  (B, 49, 512)
â”‚  7Ã—7 grid â†’ 49 tokens    â”‚  each cell = one timestep
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bidirectional LSTM Ã—2   â”‚  hidden=256 per direction
â”‚                          â”‚  Output: (B, 49, 512)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Additive Attention      â”‚  Bahdanau-style
â”‚                          â”‚  context: (B, 512)
â”‚                          â”‚  weights: (B, 49) â†’ visualizable
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Multi-Task Classification Heads    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Style  â”‚   â”‚  Genre  â”‚   â”‚  Artist  â”‚  â”‚
â”‚  â”‚ 27 cls  â”‚   â”‚ 10 cls  â”‚   â”‚  23 cls  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Each classification head: `Linear(512â†’256) â†’ ReLU â†’ Dropout(0.4) â†’ Linear(256â†’N)`

---

## ğŸ“ Project Structure

```
DeepArtNet/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ base_config.yaml          # Model + data hyperparameters
â”‚   â””â”€â”€ train_config.yaml         # Phase-wise training settings
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ wikiart/
â”‚       â”œâ”€â”€ images/               # â† Place downloaded WikiArt images here
â”‚       â”‚   â””â”€â”€ <StyleFolder>/
â”‚       â”‚       â””â”€â”€ <artist>_<painting>.jpg
â”‚       â”œâ”€â”€ style_train.csv       # âœ… Included â€” 57,025 rows
â”‚       â”œâ”€â”€ style_val.csv         # âœ… Included â€” 24,421 rows
â”‚       â”œâ”€â”€ genre_train.csv       # âœ… Included â€” 45,503 rows
â”‚       â”œâ”€â”€ genre_val.csv         # âœ… Included â€” 19,492 rows
â”‚       â”œâ”€â”€ artist_train.csv      # âœ… Included â€” 13,346 rows
â”‚       â”œâ”€â”€ artist_val.csv        # âœ… Included â€”  5,706 rows
â”‚       â”œâ”€â”€ style_class.txt       # âœ… Included â€” 27 style names
â”‚       â”œâ”€â”€ genre_class.txt       # âœ… Included â€” 10 genre names
â”‚       â””â”€â”€ artist_class.txt      # âœ… Included â€” 23 artist names
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cnn_backbone.py       # EfficientNet-B4 + projection head
â”‚   â”‚   â”œâ”€â”€ bilstm_encoder.py     # 2-layer Bidirectional LSTM
â”‚   â”‚   â”œâ”€â”€ attention.py          # Bahdanau additive attention
â”‚   â”‚   â”œâ”€â”€ classification_heads.py  # Multi-task MLP heads
â”‚   â”‚   â””â”€â”€ deepartnet.py         # Full model assembly + predict()
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py            # WikiArtDataset (reads CSVs directly)
â”‚   â”‚   â”œâ”€â”€ transforms.py         # Train / val augmentation pipelines
â”‚   â”‚   â””â”€â”€ dataloader.py         # build_dataloaders(), WeightedSampler
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py            # 3-phase Trainer class
â”‚   â”‚   â”œâ”€â”€ losses.py             # FocalLoss + MultiTaskLoss (Kendall 2018)
â”‚   â”‚   â””â”€â”€ scheduler.py          # Cosine annealing LR scheduler
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py            # Top-1/5 accuracy, confusion matrix
â”‚   â”‚   â””â”€â”€ evaluator.py          # Evaluation loop with per-class stats
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ visualization.py      # Attention heatmap overlays
â”‚       â”œâ”€â”€ checkpoint.py         # Save / load checkpoints
â”‚       â””â”€â”€ logging_utils.py      # TensorBoard + console logging
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                  # Main CLI training script
â”‚   â”œâ”€â”€ evaluate.py               # Evaluation script
â”‚   â”œâ”€â”€ inference.py              # Single-image prediction
â”‚   â””â”€â”€ download_images.py        # WikiArt image downloader helper
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_architecture.ipynb
â”‚   â”œâ”€â”€ 03_training_curves.ipynb
â”‚   â””â”€â”€ 04_attention_visualization.ipynb
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_dataset.py           # WikiArtDataset unit tests
â”‚   â”œâ”€â”€ test_model.py             # Forward pass shape tests
â”‚   â””â”€â”€ test_losses.py            # FocalLoss / MultiTaskLoss tests
â”‚
â””â”€â”€ outputs/
    â”œâ”€â”€ checkpoints/              # Saved .pth model weights
    â”œâ”€â”€ logs/                     # TensorBoard event files
    â””â”€â”€ visualizations/           # Attention map images
```

---

## âš™ï¸ Installation

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/DeepArtNet.git
cd DeepArtNet

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate      # Linux/Mac
# venv\Scripts\activate       # Windows

# 3. Install dependencies
pip install -r requirements.txt
pip install -e .

# 4. Verify
python -c "from src.models import DeepArtNet; print('Ready')"
```

---

## ğŸš€ Usage

### Train (all 3 phases)
```bash
python scripts/train.py --config configs/train_config.yaml
```

### Train a single phase
```bash
python scripts/train.py --phase 1 --epochs 20 --lr 1e-3
python scripts/train.py --phase 2 --epochs 30 --lr 5e-4 --resume outputs/checkpoints/phase1_best.pth
python scripts/train.py --phase 3 --epochs 20 --lr 1e-5 --resume outputs/checkpoints/phase2_best.pth
```

### Evaluate
```bash
python scripts/evaluate.py --checkpoint outputs/checkpoints/best_model.pth
```

### Single image inference
```bash
python scripts/inference.py --checkpoint outputs/checkpoints/best_model.pth \
    --image path/to/painting.jpg --visualize_attention
```

### Python API
```python
from src.models import DeepArtNet
from PIL import Image

model = DeepArtNet.load_from_checkpoint("outputs/checkpoints/best_model.pth")
image = Image.open("painting.jpg")
results = model.predict(image)

# {'style': {'label': 'Impressionism', 'confidence': 0.87},
#  'genre': {'label': 'landscape',     'confidence': 0.91},
#  'artist':{'label': 'Claude_Monet',  'confidence': 0.73}}
```

---

## ğŸ‹ï¸ Training Strategy

Three progressive phases, each building on the previous:

| Phase | Frozen | LR | Epochs | Batch | Purpose |
|-------|--------|----|--------|-------|---------|
| **1** | LSTM + Attention | 1e-3 | 20 | 64 | Warm up CNN features |
| **2** | Backbone blocks 0â€“2 | 5e-4 | 30 | 32 | Joint CNN-RNN learning |
| **3** | Nothing | 1e-5 | 20 | 32 | Full end-to-end fine-tuning |

### Multi-Task Loss

```
L_total = Î£áµ¢ [ 1/(2Ïƒáµ¢Â²) Â· Láµ¢ + log(Ïƒáµ¢) ]
```

Each `Láµ¢` is **Focal Loss** (Î³=2) to handle class imbalance. The Ïƒáµ¢ per task are **learned parameters** that automatically balance task contributions (Kendall et al., 2018).

---

## ğŸ“ˆ Expected Results

| Attribute | Top-1 Acc | Top-5 Acc |
|-----------|-----------|-----------|
| Style (27 cls) | ~76% | ~94% |
| Genre (10 cls) | ~83% | ~97% |
| Artist (23 cls) | ~72% | ~93% |

---

## ğŸ“š References

1. Tan et al. (2017). *ArtGAN: Artwork Synthesis with Conditional Categorical GANs.* [arXiv:1702.03410](https://arxiv.org/abs/1702.03410)
2. Saleh & Elgammal (2015). *Large-scale Classification of Fine-Art Paintings.* [arXiv:1505.00855](https://arxiv.org/abs/1505.00855)
3. Tan & Le (2019). *EfficientNet: Rethinking Model Scaling for CNNs.* [arXiv:1905.11946](https://arxiv.org/abs/1905.11946)
4. Bahdanau et al. (2015). *Neural Machine Translation by Jointly Learning to Align and Translate.* [arXiv:1409.0473](https://arxiv.org/abs/1409.0473)
5. Kendall et al. (2018). *Multi-Task Learning Using Uncertainty to Weigh Losses.* [arXiv:1705.07115](https://arxiv.org/abs/1705.07115)
6. Lin et al. (2017). *Focal Loss for Dense Object Detection.* [arXiv:1708.02002](https://arxiv.org/abs/1708.02002)

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

<p align="center"><strong>DeepArtNet</strong> â€” Teaching machines to see art the way humans do ğŸ¨</p>